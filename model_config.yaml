# ============================================================================
# Model Configuration File for iaq4j
# ============================================================================
# Scope: Any indoor air quality sensor, any indoor IAQ standard, ML-driven
# prediction.  Modify these values to adjust model architecture and behavior.

# Global settings that apply to all models
global:
  # Window size for temporal models (LSTM, CNN)
  window_size: 10
  # Number of input features (4 raw + 2 engineered: voc_ratio, abs_humidity)
  num_features: 6
  # Default device for inference (cpu/cuda)
  device: "cpu"
  # Dropout rate shared across models (can be overridden per model)
  default_dropout: 0.2

# MLP (Multi-Layer Perceptron) configuration
mlp:
  # Architecture parameters
  hidden_dims: [64, 32, 16]    # Hidden layer dimensions
  dropout: 0.2                  # Dropout rate (overrides global.default_dropout)
  activation: "relu"           # Activation function (relu/tanh/sigmoid)
  use_batch_norm: true         # Whether to use batch normalization
  # Input parameters
  input_dim: 6                 # Number of input features

# KAN (Kolmogorov-Arnold Networks) configuration
kan:
  # Architecture parameters
  hidden_dims: [32, 16]        # Hidden layer dimensions
  # Input parameters
  input_dim: 6                 # Number of input features
  # KAN-specific parameters
  grid_size: 5                 # Grid size for KAN
  spline_order: 3              # Spline order for KAN

# LSTM (Long Short-Term Memory) configuration
lstm:
  # Architecture parameters
  hidden_size: 128             # LSTM hidden state size
  num_layers: 2                # Number of LSTM layers
  dropout: 0.3                 # Dropout rate (overrides global.default_dropout)
  bidirectional: true          # Whether to use bidirectional LSTM
  # Input parameters
  window_size: 10              # Length of input sequences (overrides global.window_size)
  num_features: 6              # Number of input features (overrides global.num_features)
  # Fully connected layers after LSTM
  fc_layers: [64, 32]          # FC layer dimensions before output

# CNN (Convolutional Neural Network) configuration
cnn:
  # Convolutional layer parameters
  num_filters: [64, 128, 256]  # Number of filters for each conv layer
  kernel_sizes: [3, 3, 3]      # Kernel sizes for each conv layer
  dropout: 0.3                 # Dropout rate (overrides global.default_dropout)
  # Input parameters
  window_size: 10              # Length of input sequences (overrides global.window_size)
  num_features: 6              # Number of input features (overrides global.num_features)
  # Fully connected layers after convolutions
  fc_layers: [128, 64]         # FC layer dimensions before output

# Sensor configuration — valid ranges for outlier filtering during preprocessing
sensor:
  type: bme680
  # Column names — single source of truth for pipeline field references
  features: [temperature, rel_humidity, pressure, voc_resistance]
  target: iaq
  valid_ranges:
    temperature: [-40, 85]           # °C (BME680 full operating range)
    rel_humidity: [0, 100]           # % r.H.
    pressure: [300, 1100]            # hPa
    voc_resistance: [1000, 2000000]  # Ohm (<1kΩ = sensor fault, >2MΩ = unreasonable)
    iaq_accuracy: [2, 3]             # BSEC accuracy (0=unreliable, 1=low, 2=medium, 3=high)

# IAQ standard — selects the target scale and category breakpoints
iaq_standard:
  type: bsec                         # Registered IAQStandard name (see app/builtin_profiles.py)

# Training configuration — read by TrainingPipeline and train_model()
training:
  epochs: 200
  batch_size: 32
  learning_rate: 0.001
  test_size: 0.2               # validation split ratio
  random_state: 42
  min_samples: 100             # minimum rows required after ingestion
  # LR scheduler (ReduceLROnPlateau)
  lr_scheduler_patience: 10
  lr_scheduler_factor: 0.5
  # TensorBoard
  tensorboard_enabled: true          # write TensorBoard events during training
  tensorboard_log_dir: "runs"        # base directory for TensorBoard logs
  tensorboard_histogram_freq: 50     # log weight/gradient histograms every N epochs (0 = off)